<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏°.2/1</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
    <style>
        body { font-family: 'Sarabun', sans-serif; display: flex; flex-direction: column; align-items: center; background-color: #f0f4f8; margin: 0; padding: 20px; }
        .header { text-align: center; margin-bottom: 20px; }
        h2 { color: #003366; margin: 0; }
        h1 { color: #1a73e8; margin: 5px 0; font-size: 1.4rem; }
        .video-container { position: relative; width: 100%; max-width: 500px; border-radius: 15px; overflow: hidden; box-shadow: 0 8px 20px rgba(0,0,0,0.2); background: #222; }
        video { width: 100%; display: block; transform: scaleX(-1); } /* Mirror mode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤ */
        canvas { position: absolute; top: 0; left: 0; transform: scaleX(-1); }
        .status-pill { margin-top: 20px; padding: 12px 25px; background: white; border-radius: 30px; border: 2px solid #1a73e8; font-weight: bold; font-size: 1.1rem; color: #333; box-shadow: 0 4px 10px rgba(0,0,0,0.1); }
    </style>
</head>
<body>

    <div class="header">
        <h2>‡πÇ‡∏£‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏õ‡∏£‡∏≤‡∏à‡∏¥‡∏ì‡∏£‡∏≤‡∏©‡∏é‡∏£‡∏≠‡∏≥‡∏£‡∏∏‡∏á</h2>
        <h1>‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô ‡∏°.2/1</h1>
    </div>

    <div class="video-container" id="container">
        <video id="video" autoplay muted playsinline></video>
    </div>

    <div class="status-pill" id="status">‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡∏£‡∏∞‡∏ö‡∏ö AI...</div>

    <script>
        const video = document.getElementById('video');
        const statusText = document.getElementById('status');

        const emotionThai = {
            neutral: "‡∏õ‡∏Å‡∏ï‡∏¥ üòê", happy: "‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç üòä", sad: "‡πÄ‡∏®‡∏£‡πâ‡∏≤ üò¢",
            angry: "‡πÇ‡∏Å‡∏£‡∏ò üò†", fearful: "‡∏Å‡∏•‡∏±‡∏ß üò®", disgusted: "‡∏£‡∏±‡∏á‡πÄ‡∏Å‡∏µ‡∏¢‡∏à ü§¢", surprised: "‡∏ï‡∏Å‡πÉ‡∏à üò≤"
        };

        async function initAI() {
            // ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÇ‡∏´‡∏•‡∏î Model ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ (vladmandic models)
            const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';
            
            try {
                statusText.innerText = "1/2 ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤...";
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                statusText.innerText = "2/2 ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå...";
                await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
                
                statusText.innerText = "‡πÇ‡∏´‡∏•‡∏î AI ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á...";
                setupCamera();
            } catch (err) {
                statusText.innerText = "‚ùå ‡πÇ‡∏´‡∏•‡∏î AI ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠";
                console.error("Model Load Error:", err);
            }
        }

        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: "user", width: 640, height: 480 } 
                });
                video.srcObject = stream;
            } catch (err) {
                statusText.innerText = "‚ùå ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡πÇ‡∏õ‡∏£‡∏î‡∏Å‡∏î‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï)";
            }
        }

        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video);
            document.getElementById('container').append(canvas);
            
            const displaySize = { width: video.clientWidth, height: video.clientHeight };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceExpressions();

                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                
                // ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                faceapi.draw.drawDetections(canvas, resizedDetections);

                if (detections.length > 0) {
                    const expressions = detections[0].expressions;
                    const topEmotion = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
                    statusText.innerText = "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: " + emotionThai[topEmotion];
                } else {
                    statusText.innerText = "‡∏°‡∏≠‡∏á‡∏°‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç";
                }
            }, 400);
        });

        // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
        window.onload = initAI;
    </script>
</body>
</html>
